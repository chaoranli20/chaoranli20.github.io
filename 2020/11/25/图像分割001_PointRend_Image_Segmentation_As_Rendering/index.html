<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="论文阅读摘要 把图像分割视作一个渲染任务，渲染指把一个类似3Dmesh的模型表示为a regular grid of pixels的方法 提出PointRend神经网络模型，这个模型通过迭代细分算法把基于点的分割预测建模为适应性的挑选位置 pointrend能够被插入现存的语义和实例分割网络，下文的实验就使用了pointrend替换了mask rcnn的默认mask head">
<meta property="og:type" content="article">
<meta property="og:title" content="图像分割001_PointRend_Image_Segmentation_As_Rendering">
<meta property="og:url" content="http://example.com/2020/11/25/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2001_PointRend_Image_Segmentation_As_Rendering/index.html">
<meta property="og:site_name">
<meta property="og:description" content="论文阅读摘要 把图像分割视作一个渲染任务，渲染指把一个类似3Dmesh的模型表示为a regular grid of pixels的方法 提出PointRend神经网络模型，这个模型通过迭代细分算法把基于点的分割预测建模为适应性的挑选位置 pointrend能够被插入现存的语义和实例分割网络，下文的实验就使用了pointrend替换了mask rcnn的默认mask head">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/images/001_pointrend.PNG">
<meta property="article:published_time" content="2020-11-25T08:45:13.000Z">
<meta property="article:modified_time" content="2020-11-25T09:03:48.100Z">
<meta property="article:author" content="superran">
<meta property="article:tag" content="图像分割">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/001_pointrend.PNG">

<link rel="canonical" href="http://example.com/2020/11/25/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2001_PointRend_Image_Segmentation_As_Rendering/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>图像分割001_PointRend_Image_Segmentation_As_Rendering | </title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title"></h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-本站首页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>本站首页</a>

  </li>
        <li class="menu-item menu-item-关于我">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于我</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/25/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2001_PointRend_Image_Segmentation_As_Rendering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="superran">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          图像分割001_PointRend_Image_Segmentation_As_Rendering
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-11-25 16:45:13 / 修改时间：17:03:48" itemprop="dateCreated datePublished" datetime="2020-11-25T16:45:13+08:00">2020-11-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">图像处理</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><ul>
<li>把图像分割视作一个渲染任务，渲染指把一个类似3Dmesh的模型表示为a regular grid of pixels的方法</li>
<li>提出PointRend神经网络模型，这个模型通过迭代细分算法把基于点的分割预测建模为适应性的挑选位置</li>
<li>pointrend能够被插入现存的语义和实例分割网络，下文的实验就使用了pointrend替换了mask rcnn的默认mask head<a id="more"></a>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3></li>
<li>图像分割最近常选用基于CNN的方法，CNN通常在规律性的网格上进行操作，<strong>CNN方法存在问题</strong>：<ul>
<li>方便，但是对图像分割来说会有一些不必要的计算</li>
<li>这些网络预测的图应当是光滑的，例如相邻像素应当有相同标签</li>
<li>规律的网格会不必要的过采样光滑区域，但是对边界区域欠采样</li>
</ul>
</li>
<li><strong>图形渲染中也研究这样的问题</strong><ul>
<li>渲染时把3D模型渲染为栅格化图像</li>
<li>尽管输出是在规律的格子上，但是计算不会在网格上平均分配</li>
</ul>
</li>
<li><strong>做法</strong><ul>
<li>把图像分割看做渲染问题，，使用细分策略选择一组不均匀点集来计算标签，只在选择的点上做预测</li>
<li>先插入CNN特征图f(xi, yi)为选择的点提取特征表示，然后使用一个小的子网络做预测，输出高分辨率预测结果p(xi’, yi’)</li>
</ul>
</li>
<li><strong>相关知识</strong><ul>
<li>实例分割中，每一个被检测的物体都会被预测出一张二进制的前景vs背景map</li>
<li>实例分割的基础架构常常是Mask R-CNN，语义分割基础架构常常是FCN</li>
</ul>
</li>
</ul>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><ul>
<li><strong>渲染</strong><ul>
<li>好的方法：细分(subdivision)和适应性采样(adaptive sampling)在像素值变化大的地方定义了一个粗糙的光栅；射线追踪(ray-tracing)渲染常使用过采样(采样比输出网格要密集的点)来避免混淆(aliasing)的影响</li>
<li>论文使用subdivision方法</li>
</ul>
</li>
<li><strong>非均匀网格表示</strong><ul>
<li>3D视觉任务例如3D形状识别中，大的3D网格是不可行的，基于CNN的方法最多做到64*64*64</li>
<li>最近的非均匀网格表示方法：meshes，signed distance functions，octrees</li>
<li>和符号距离函数(signed distance functions)方法相同，论文可以在任何一点计算分割值</li>
<li>有人提出了在输入图像上做非均匀下采样然后使用标准语义分割网络的方法，和他不同，论文在输出上做非均匀采样</li>
</ul>
</li>
<li><strong>实例分割</strong><ul>
<li>Mask RCNN是基于区域的，通常在28*28的网格内预测mask，对小物体而言这足够了，对大物体而言它在细节上过于光滑，在输出上产生了滴状(blobby)</li>
<li>把像素分组(group pixels)来表示物体mask可以产生更细节的输出，但是很慢</li>
<li>Tensormask是一个滑动窗口方法，使用一个复杂网络来为大物体预测高分辨率mask，但它精度不好</li>
<li>论文中把PointRend加到了基于区域的分割方法上，效果很好</li>
</ul>
</li>
<li><strong>语义分割</strong><ul>
<li>FCN预测的输出比输入的网格有更小的分辨率，使用双线性上采样来恢复8-16倍的分辨率，当用卷积层代替下采样层时结果或许会变好，但也会cost more</li>
<li>encoder-decoder架构在编码器中下采样网格表示，在解码器中上采样网格表示，使用跳过的连接恢复筛选的信息</li>
<li>现在的方法是在双线性插值之前把扩张卷积和编码解码架构combine，以在比输入图像四倍稀疏的网格上产生输出</li>
<li>论文提出了一种能够在和输入图像同样密度的网格上预测精细细节的方法</li>
</ul>
</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><ul>
<li>类比渲染和图像分割</li>
</ul>
<table>
<thead>
<tr>
<th>渲染(rendering)</th>
<th>分割(segmentation)</th>
</tr>
</thead>
<tbody><tr>
<td>底层实体连续</td>
<td>实体在网络特征图中被编码，通过插值得到任意点的值</td>
</tr>
<tr>
<td>physical occupancy和其他属性能够在任意点被查询</td>
<td>分割是occupancy map</td>
</tr>
<tr>
<td>查询时根据physical和几何特性</td>
<td>训练的参数对应这些特性</td>
</tr>
<tr>
<td>输出规律网格</td>
<td>分割输出看做规律网格</td>
</tr>
</tbody></table>
<ul>
<li><p><strong>PointRend的输入输出</strong></p>
<ul>
<li>输入是一个或多个典型的CNN特征图，这些特征图有C个通道，即f∈R<sup>C*H*W</SUP>，都是规律网格(通常设置为图像网格的4倍到16倍稀疏)</li>
<li>为K类标签输出预测p∈R<sup>K*H’*W’</SUP>(在不同分辨率，通常是更高分辨率)</li>
</ul>
</li>
<li><p><strong>PointRend通常包括三个部件</strong></p>
<ul>
<li>点选择策略，选择少量真值点做预测</li>
<li>针对性的特征表示，对每个被选择的点进行，使用f上这个点的四个最近邻插值得到；这样就能利用在f的通道维度编码的子像素信息来预测比f更高分辨率的分割<strong>不懂</strong></li>
<li>point-head，训练一个小的神经网络基于上面的特征表示为每个点独立的预测标签</li>
</ul>
</li>
<li><p><strong>PointRend</strong>能够用于实例分割和语义分割</p>
<ul>
<li>实例分割中，PointRend用于每个区域</li>
<li>语义分割中，整个图被看做一整个区域</li>
</ul>
</li>
<li><p><strong>点选择策略</strong></p>
<ul>
<li>凭直觉的，这些点应该选的离高频区域近一些</li>
<li>develop this idea for inference and training</li>
<li>推断<ul>
<li>当一个值和它的邻居们显著不同时，选它</li>
<li>其他的值通过插值已经得到的值得到(starting from a coarse grid)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; coarse to fine fashion, iteratively &quot;render&quot; the output mask</span><br><span class="line">在规律网格上用标准的分割预测方法做预测; &#x2F;&#x2F; 最粗糙级</span><br><span class="line">while(分割未上采样至想要的分辨率)&#123;</span><br><span class="line">    用双线性插值上采样上一个预测的分割;</span><br><span class="line">    选出N个最模棱两可的点; &#x2F;&#x2F; 例如对一个二分类mask可能性为0.5</span><br><span class="line">    使用下面讲的针对性特征表示方法分别表示这N个点并计算它们的标签;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>输出分辨率是M<em>M，输入分辨率是M0</em>M0时，PointRend需要不多于Nlog<sub>2</sub>(M/M<sub>0</sub>)次点预测，这比M*M小多了</li>
</ul>
</li>
<li>训练<ul>
<li>inference中的策略是系列性步骤，不利于进行反向传播，所以使用了基于随机采样的非迭代策略</li>
<li>在特征图上选择N个点，偏向不确定的区域，但是也保留了均匀覆盖(uniform coverage)的一些特性，包含三个原则<ul>
<li>多生成(over generation)，按均匀分布随机生成kN个候选点(k&gt;1)</li>
<li>重要性采样(importance sampling)，在kN个点插入粗糙预测值并计算任务特定的不确定性估计，从而关注有不确定性粗糙预测的点，最不确定的βN个点从kN个点中选出(β∈[0, 1])</li>
<li>覆盖(coverage)，剩余的(1-β)N个点从均匀分布采样</li>
</ul>
</li>
<li>训练时，预测和损失函数只在N个采样点上计算(除粗糙分割之外)</li>
<li>这个设计和在Fast-RCNN中的RPN + Fast-RCNN并行训练(它的推理也是序列性的)相同</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>针对性表示和Point Head</strong></p>
<ul>
<li>融合精细特征和粗糙预测特征两类特征来对选择的点进行特征表示</li>
<li>精细特征<ul>
<li>从CNN特征图上为每一个选择的点提取一个特征向量</li>
<li>由于选择的点是实值二维坐标，我们在特征图上做双线性插值来计算特征向量(这是标准步骤，参照文献[19, 17, 9])</li>
<li>可以在单一特征图上提取特征向量(例如ResNet的res2)，也可以从多个特征图上提取特征向量并用Hypercolumn方法连接(如res2-res5)</li>
</ul>
</li>
<li>粗糙预测特征<ul>
<li>为什么要用这个特征<ul>
<li>精细特征不包括区域特定信息，所以被两个实例的bounding box覆盖的一个点会有相同的精细特征，但是这个点只能作为一个实例的前景。所以在不同区域可能会为同一个点预测不同的标签的实例分割任务中，需要附加的区域特定信息。</li>
<li>精细特征或许只包含低维信息</li>
</ul>
</li>
<li>所以使用了从网络中来的粗糙分割预测，例如对每个点是个表征K类预测的K维向量。使用的粗糙预测和现存的架构的输出相似，在训练时和现存的模型使用相同的监督方法。</li>
<li>实例分割时，粗糙预测可以是Mask RCNN中a lightweight 7*7 resolution mask head的输出；对语义分割，可以是基于步长16的特征图的预测</li>
</ul>
</li>
<li>Point head<ul>
<li>使用多层感知机(MLP)，为所有点和区域共享权重</li>
</ul>
</li>
<li><img src="/images/001_pointrend.PNG" alt="应用于实例分割的pointrend"></li>
</ul>
</li>
</ul>
<h3 id="实例分割实验"><a href="#实例分割实验" class="headerlink" title="实例分割实验"></a>实例分割实验</h3><ul>
<li>数据集<ul>
<li>coco和cityscapes；跑了3次coco和5次cityscapes，记录了标准mask AP metric的中位数</li>
<li>coco有80个实例级注释的目录，论文在train2017(有118k图片)上训练，在val2017(5k图片)上报告结果</li>
<li>参考文献[14]说coco的AP不准确，所以依然用上面训练的模型，但用LVIS重新评估了预测结果，记为AP*</li>
</ul>
</li>
<li>架构<ul>
<li>使用Mask RCNN + ResNet-50 + FPN的backbone(用来做特征提取的网络)</li>
<li>Mask RCNN中默认的mask head是一个区域性FCN，论文中标记为4 * conv(4层有256个输出通道的3<em>3卷积被应用于14</em>14的输入特征图，2<em>2的核把它转化为28</em>28，最终一个1*1的卷积预测mask logits)，使用这作为baseline(证明设计的对比实验)</li>
<li>head获取网络输出内容，利用提取的特征做出预测</li>
</ul>
</li>
<li>粗糙预测部分<ul>
<li>替换4*conv，使用了类似Mask RCNN的box head，产生7*7的mask预测<ul>
<li>对每个bounding box，从FPN的P2级使用双线性插值提取14*14的特征图，特征在bounding box内的规律网格计算，这一步可以看做ROLAlign的简单版本</li>
<li>使用步长2输出通道256的2*2卷积层+Relu层把尺度减小到7*7</li>
<li>然后和Mask RCNN的box head类似，有两个1024宽的隐藏层的MLP被用于产生7*7的mask预测，ReLU被用于MLP的隐藏层，sigmoid激活函数作用于MLP的输出</li>
</ul>
</li>
</ul>
</li>
<li>PointRend<ul>
<li>对每个被选择的点，，一个K维的特征向量被通过双线性插值从粗糙预测head中提取出来</li>
<li>PointRend也从FPN的P2级插值了256维的特征向量，这一级步长是4</li>
<li>拼接这两类特征向量</li>
<li>使用有3个隐藏层256个通道的MLP在选择的点上做K类预测，在MLP的每个层，使用K个粗糙预测特征补充256维通道，来作为下一层的输入特征，在MLP内使用ReLU，对它的输出使用sigmod</li>
</ul>
</li>
<li>训练<ul>
<li>使用标准的1*训练规程，默认使用detection2做数据增强</li>
<li>使用k=3, β=0.75采样14*14个点</li>
<li>使用0.5和来自粗糙预测的插值的ground truth class可能性之间的距离作为针对点的不确定性度量</li>
<li>for a predicted box with ground-truth class c，对第c个MLP输出的14*14个点的二元交叉熵损失求和</li>
<li>粗糙预测部分使用平均交叉熵损失</li>
<li>训练时box和mask head并行，而不是像推断中的级联</li>
</ul>
</li>
<li>主要结果<ul>
<li>比较PointRend和mask rcnn默认的4*conv head</li>
<li>AP使用交并比，偏向物体内像素，对边缘质量不敏感</li>
</ul>
</li>
</ul>
<h3 id="语义分割实验"><a href="#语义分割实验" class="headerlink" title="语义分割实验"></a>语义分割实验</h3><ul>
<li>把PointRend分别加到现有的两个语义分割模型DeeplabV3和SemanticFPN(这是一个解码-编码架构)中</li>
<li>PointRend之所以能做高分辨率输出，是因为忽视了粗糙预测就已经足够了的区域</li>
<li>实现细节<ul>
<li>复现上面的两种模型，根据他们论文中的训练步骤和参数</li>
<li>使用和实例分割中相同的PointRend架构，粗糙预测来自语义分割网络，对DeeplabV3精细特征从res2插值，对SemanticFPN精细特征从P2中插值</li>
<li>训练中采样的点数as many as there are on a stride 16 feature map of the input</li>
<li>k=3，β=0.75，N=8096</li>
<li>使用最确信类和第二确信类之间的距离衡量不确定性</li>
</ul>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/" rel="tag"># 图像分割</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/25/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B001_EfficientDet_Scalable_and_Efficient_Object_Detection/" rel="prev" title="目标检测001_EfficientDet_Scalable_and_Efficient_Object_Detection">
      <i class="fa fa-chevron-left"></i> 目标检测001_EfficientDet_Scalable_and_Efficient_Object_Detection
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB"><span class="nav-number">1.</span> <span class="nav-text">论文阅读</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">1.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Related-Work"><span class="nav-number">1.3.</span> <span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Method"><span class="nav-number">1.4.</span> <span class="nav-text">Method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.5.</span> <span class="nav-text">实例分割实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.6.</span> <span class="nav-text">语义分割实验</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">superran</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/chaoranli20" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chaoranli20" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fab fa-angellist"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">superran</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
